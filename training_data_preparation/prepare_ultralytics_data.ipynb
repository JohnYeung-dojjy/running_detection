{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare LSTM training data using [ultralytics pose estimation model](https://github.com/ultralytics/ultralytics) for better robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from ultralytics.models import YOLO\n",
    "from ultralytics.engine.results import Results\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSE_OUTPUT_LABELS = [\n",
    "    \"nose_x\", \"nose_y\",\n",
    "    \"left_eye_x\", \"left_eye_y\",\n",
    "    \"right_eye_x\", \"right_eye_y\",\n",
    "    \"left_ear_x\", \"left_ear_y\",\n",
    "    \"right_ear_x\", \"right_ear_y\",\n",
    "    \"left_shoulder_x\", \"left_shoulder_y\",\n",
    "    \"right_shoulder_x\", \"right_shoulder_y\",\n",
    "    \"left_elbow_x\", \"left_elbow_y\",\n",
    "    \"right_elbow_x\", \"right_elbow_y\",\n",
    "    \"left_wrist_x\", \"left_wrist_y\",\n",
    "    \"right_wrist_x\", \"right_wrist_y\",\n",
    "    \"left_hip_x\", \"left_hip_y\",\n",
    "    \"right_hip_x\", \"right_hip_y\",\n",
    "    \"left_knee_x\", \"left_knee_y\",\n",
    "    \"right_knee_x\", \"right_knee_y\",\n",
    "    \"left_ankle_x\", \"left_ankle_y\",\n",
    "    \"right_ankle_x\", \"right_ankle_y\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure working directory is correct\n",
    "if os.getcwd().endswith(\"training_data_preparation\"):\n",
    "    PROJECT_DIR = Path(\"..\")\n",
    "else:\n",
    "    PROJECT_DIR = Path()\n",
    "PROJECT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = PROJECT_DIR / \"Dataset\" / \"KTH\"\n",
    "POSE_MODEL_DIR = PROJECT_DIR / \"models\" / \"pose\"\n",
    "\n",
    "DATASET_SAVE_DIR = PROJECT_DIR / \"TrainingData\" / \"ultralytics\"\n",
    "DATASET_RAW_SAVE_DIR = DATASET_SAVE_DIR / \"raw\"\n",
    "DATASET_NORMALIZED_SAVE_DIR = DATASET_SAVE_DIR / \"normalized\"\n",
    "\n",
    "if not DATASET_RAW_SAVE_DIR.exists():\n",
    "    DATASET_RAW_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "if not DATASET_NORMALIZED_SAVE_DIR.exists():\n",
    "    DATASET_NORMALIZED_SAVE_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERWRITE_DATASET = False # Whether to overwrite existing dataset parquet files if they already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = \"n\" # nano model is accurate enough\n",
    "pose_model = YOLO(POSE_MODEL_DIR / f\"yolo11{model_size}-pose.pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_raw_coordinates(results: list[Results]):\n",
    "    \"\"\"Process the pose model results' raw x,y coordinates and put them into a pandas dataframe.\"\"\"\n",
    "    no_detection = np.zeros(len(POSE_OUTPUT_LABELS))\n",
    "    con = []\n",
    "    for result in results:\n",
    "        kp_xy = result.keypoints.xy.flatten().cpu().numpy()\n",
    "        if len(kp_xy) == 0:\n",
    "            con.append(no_detection)\n",
    "        elif len(kp_xy) == len(POSE_OUTPUT_LABELS):\n",
    "            con.append(kp_xy)\n",
    "        else:\n",
    "            # multiple person detected, but the KTH dataset has only one person in a video.\n",
    "            # we just ignore this frame\n",
    "            continue\n",
    "    return pd.DataFrame(con, columns=POSE_OUTPUT_LABELS)\n",
    "\n",
    "def save_normalized_coordinates(results: list[Results]):\n",
    "    \"\"\"Process the pose model results' normalized x,y coordinates and put them into a pandas dataframe.\"\"\"\n",
    "    no_detection = np.zeros(len(POSE_OUTPUT_LABELS))\n",
    "    con = []\n",
    "    for result in results:\n",
    "        kp_xy = result.keypoints.xyn.flatten().cpu().numpy()\n",
    "        if len(kp_xy) == 0:\n",
    "            con.append(no_detection)\n",
    "        elif len(kp_xy) == len(POSE_OUTPUT_LABELS):\n",
    "            con.append(kp_xy)\n",
    "        else:\n",
    "            # multiple person detected, but the KTH dataset has only one person in a video.\n",
    "            # we just ignore this frame\n",
    "            continue\n",
    "    return pd.DataFrame(con, columns=POSE_OUTPUT_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Videos and save the pose estimation results to parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in [\"jogging\", \"walking\", \"running\"]:\n",
    "    video_filenames = glob(str(DATASET_DIR/label) + \"/*.avi\")\n",
    "\n",
    "    for video_filename in tqdm(video_filenames, desc=label):\n",
    "        results = pose_model.track(\n",
    "            source=video_filename,\n",
    "            show=False,\n",
    "            verbose=False,\n",
    "            stream=True,\n",
    "        )\n",
    "        results = list(results)\n",
    "        df = save_raw_coordinates(results)\n",
    "        normalized_df = save_normalized_coordinates(results)\n",
    "        parquet_name = os.path.basename(video_filename).rsplit('.')[0]\n",
    "\n",
    "        raw_save_path = DATASET_SAVE_DIR / \"raw\" / f\"{parquet_name}.parquet\"\n",
    "        normalized_save_path = DATASET_SAVE_DIR / \"normalized\" / f\"{parquet_name}.parquet\"\n",
    "        if not raw_save_path.exists() or OVERWRITE_DATASET:\n",
    "            df.to_parquet(raw_save_path)\n",
    "        if not normalized_save_path.exists() or OVERWRITE_DATASET:\n",
    "            normalized_df.to_parquet(DATASET_SAVE_DIR / \"normalized\" / f\"{parquet_name}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "running_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
